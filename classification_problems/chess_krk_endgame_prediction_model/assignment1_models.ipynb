{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id3ICgB-JVSK"
      },
      "source": [
        "# Assigment 01:Data Science programing : Modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d2rZcjMTH4cT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np \n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mocd4QhPJYoK"
      },
      "source": [
        "## Read Source Data ( pre-processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ro0iTQhgH8q0"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_parquet(\"X_train_krk.parquet\")\n",
        "X_test = pd.read_parquet(\"X_test_krk.parquet\")\n",
        "y_train = pd.read_parquet(\"y_train_krk.parquet\")\n",
        "y_test = pd.read_parquet(\"y_test_krk.parquet\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "eTRoytz19bS_",
        "outputId": "586df4b0-55fa-4a5d-eccc-883369083990"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>white_king_file_ohe_b</th>\n",
              "      <th>white_king_file_ohe_c</th>\n",
              "      <th>white_king_file_ohe_d</th>\n",
              "      <th>white_king_rank_ohe_2</th>\n",
              "      <th>white_king_rank_ohe_3</th>\n",
              "      <th>white_king_rank_ohe_4</th>\n",
              "      <th>white_rook_file_ohe_b</th>\n",
              "      <th>white_rook_file_ohe_c</th>\n",
              "      <th>white_rook_file_ohe_d</th>\n",
              "      <th>white_rook_file_ohe_e</th>\n",
              "      <th>...</th>\n",
              "      <th>black_king_file_ohe_f</th>\n",
              "      <th>black_king_file_ohe_g</th>\n",
              "      <th>black_king_file_ohe_h</th>\n",
              "      <th>black_king_rank_ohe_2</th>\n",
              "      <th>black_king_rank_ohe_3</th>\n",
              "      <th>black_king_rank_ohe_4</th>\n",
              "      <th>black_king_rank_ohe_5</th>\n",
              "      <th>black_king_rank_ohe_6</th>\n",
              "      <th>black_king_rank_ohe_7</th>\n",
              "      <th>black_king_rank_ohe_8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   white_king_file_ohe_b  white_king_file_ohe_c  white_king_file_ohe_d  \\\n",
              "0                      0                      0                      1   \n",
              "1                      0                      0                      1   \n",
              "2                      0                      0                      1   \n",
              "3                      1                      0                      0   \n",
              "4                      0                      1                      0   \n",
              "\n",
              "   white_king_rank_ohe_2  white_king_rank_ohe_3  white_king_rank_ohe_4  \\\n",
              "0                      0                      1                      0   \n",
              "1                      0                      1                      0   \n",
              "2                      1                      0                      0   \n",
              "3                      0                      0                      0   \n",
              "4                      1                      0                      0   \n",
              "\n",
              "   white_rook_file_ohe_b  white_rook_file_ohe_c  white_rook_file_ohe_d  \\\n",
              "0                      0                      0                      1   \n",
              "1                      0                      0                      0   \n",
              "2                      0                      0                      0   \n",
              "3                      0                      0                      0   \n",
              "4                      0                      0                      0   \n",
              "\n",
              "   white_rook_file_ohe_e  ...  black_king_file_ohe_f  black_king_file_ohe_g  \\\n",
              "0                      0  ...                      0                      0   \n",
              "1                      0  ...                      0                      0   \n",
              "2                      0  ...                      1                      0   \n",
              "3                      1  ...                      0                      1   \n",
              "4                      0  ...                      0                      0   \n",
              "\n",
              "   black_king_file_ohe_h  black_king_rank_ohe_2  black_king_rank_ohe_3  \\\n",
              "0                      1                      0                      0   \n",
              "1                      0                      0                      1   \n",
              "2                      0                      0                      0   \n",
              "3                      0                      0                      0   \n",
              "4                      1                      0                      0   \n",
              "\n",
              "   black_king_rank_ohe_4  black_king_rank_ohe_5  black_king_rank_ohe_6  \\\n",
              "0                      0                      0                      0   \n",
              "1                      0                      0                      0   \n",
              "2                      0                      0                      0   \n",
              "3                      1                      0                      0   \n",
              "4                      0                      0                      1   \n",
              "\n",
              "   black_king_rank_ohe_7  black_king_rank_ohe_8  \n",
              "0                      0                      1  \n",
              "1                      0                      0  \n",
              "2                      0                      0  \n",
              "3                      0                      0  \n",
              "4                      0                      0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt7dx8oYJf7x"
      },
      "source": [
        "## Performace table: model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jQiihSwVKFKC"
      },
      "outputs": [],
      "source": [
        "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUNruqHHKIFW"
      },
      "source": [
        "## Modeling \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVD9IKY6KURJ"
      },
      "source": [
        "### D-tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yYXP6kSKWPK",
        "outputId": "80d8790e-1462-46c5-ef35-d5d7491f7c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model: D-Tree Unpruned, Data: X_test, Accuracy=0.6142513 Precision=0.6164920 Recall=0.6142513 F1=0.6150063\n"
          ]
        }
      ],
      "source": [
        "dtree = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "c_matrix = confusion_matrix(y_test, dtree.predict(X_test))\n",
        "y_pred = (dtree.predict(X_test))\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "print(f\" Model: D-Tree Unpruned, Data: X_test, Accuracy={accuracy:.7f} Precision={precision:.7f} Recall={recall:.7f} F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"D Tree Unpruned\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkPnvf339bTE"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PefkS3IsKc52",
        "outputId": "268b1cdf-fac8-4917-9955-c81a7dac00fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_25144\\1046076677.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model: Random Forest, Data: X_test, Accuracy=0.6166596 Precision=0.6101316 Recall=0.6166596 F1=0.6095741\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# train a random forest model\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on the test set\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# evaluate the model using confusion matrix, classification report, and accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "print(f\" Model: Random Forest, Data: X_test, Accuracy={accuracy:.7f} Precision={precision:.7f} Recall={recall:.7f} F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vGZEobtS_IY",
        "outputId": "b909445e-43ed-4069-bbaf-e501c29b0c6a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model: Random Forest, Data: X_test, Accuracy=0.3986400 Precision=0.3698369 Recall=0.3986400 F1=0.3724408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train a logistic regression model\n",
        "lr = LogisticRegression(max_iter=10000)\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the logistic regression model\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "prec_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "rec_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "\n",
        "print(f\" Model: Random Forest, Data: X_test, Accuracy={acc_lr:.7f} Precision={prec_lr:.7f} Recall={rec_lr:.7f} F1={f1_lr:.7f}\")\n",
        "\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXU4mJdy9bTG"
      },
      "source": [
        "### SVM "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuHvPXUCWOTZ",
        "outputId": "cfb0465c-11a1-4fb5-eb47-1aca3fccba3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model: SVM, Data: X_test\n",
            " Accuracy=0.7420314\n",
            " Precision=0.7386576\n",
            " Recall=0.7420314\n",
            " F1=0.7372575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Train an SVM model\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the SVM model\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "prec_svm = precision_score(y_test, y_pred_svm, average='weighted')\n",
        "rec_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
        "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
        "\n",
        "print(f\" Model: SVM, Data: X_test\\n Accuracy={acc_svm:.7f}\\n Precision={prec_svm:.7f}\\n Recall={rec_svm:.7f}\\n F1={f1_svm:.7f}\")\n",
        "\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM\", \n",
        "                                                    'Accuracy': [acc_svm], \n",
        "                                                    'Precision': [prec_svm], \n",
        "                                                    'Recall': [rec_svm], \n",
        "                                                    'F1': [f1_svm]\n",
        "                                                     }, index=[0])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h2Uj6uGWRRr"
      },
      "source": [
        "## Choosing the right metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiT4BrDZ9bTJ"
      },
      "source": [
        "1. In order to find the best suitable metric, we need to analyize different possible errors our model can produce.\n",
        "2. We have a multi classification data with 18 classes. Hence our confusion matrix is quite complicated to understand.\n",
        "3. However, our analysis can be made simple by considering one of the classes and examining the potential errors for that class.\n",
        "4. **False positive**: A false positive occurs when the model predicts a game to end in a certain number of moves, but the actual outcome is different. For example, if the model predicts that a game will end in 5 moves, but the actual outcome is a draw, then this would be a false positive for the \"5 moves\" class.\n",
        "5. **False negative**: A false negative occurs when the model fails to predict a game to end in a certain number of moves, but the actual outcome is that number of moves. For example, if the model fails to predict that a game will end in 10 moves, but the actual outcome is 10 moves, then this would be a false negative for the \"10 moves\" class.\n",
        "\n",
        "\n",
        "Therefore, in my case, it is important to minimize both the errors, that is to balance both precision and Recall. Hence the f1-score, the harmonic mean of both Precision and Recall would be the best metric for our business problem.\n",
        "\n",
        "\n",
        "Therefore, **Best Metric** is **\"F1-Score\"**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yPfXHA3A9bTK"
      },
      "source": [
        "## Cross Validation using Random and Grid Search for our models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z7EyGlP9bTK"
      },
      "source": [
        "###  Dtree : Random Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwhyG2ym9bTL",
        "outputId": "043a6f2c-a9c3-4349-ea66-16bca7901caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Model: D-Tree, best parameters: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 45}\n",
            "Model: D-Tree: Random Search CV, \n",
            "Data: X_test\n",
            " Accuracy=0.6362091\n",
            " Precision=0.6342953\n",
            " Recall=0.6362091\n",
            " F1=0.6343132\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "param_dist = {\n",
        "    'max_depth': np.arange(35, 100, 1),\n",
        "    'min_samples_split': np.arange(5, 100, 5),\n",
        "    'min_samples_leaf': [1, 100, 1],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "rs = RandomizedSearchCV(dt, param_distributions=param_dist, scoring='f1_weighted', cv=5,   n_jobs=-1,\n",
        "                                 verbose= 1, n_iter=100)\n",
        "\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "best_params = rs.best_params_\n",
        "print(f\"Model: D-Tree, best parameters: {best_params}\")\n",
        "dt_best = DecisionTreeClassifier(**best_params)\n",
        "\n",
        "dt_best.fit(X_train, y_train)\n",
        "y_pred = dt_best.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "print(f\"Model: D-Tree: Random Search CV, \\nData: X_test\\n Accuracy={accuracy:.7f}\\n Precision={precision:.7f}\\n Recall={recall:.7f}\\n F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"D-Tree, Random Search CV\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGzSblJE9bTL"
      },
      "source": [
        "### D_Tree Grid Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "eb7Nje7v9bTM",
        "outputId": "0cbb43dd-83f5-4a60-9937-0c3df2ca61a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "Fitting 5 folds for each of 900 candidates, totalling 4500 fits\n",
            "Model: D-Tree: Grid Search CV, \n",
            "Data: X_test\n",
            " Accuracy=0.6408840\n",
            " Precision=0.5613594\n",
            " Recall=0.5744256\n",
            " F1=0.5665880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
            "500 fits failed out of a total of 4500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "500 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
            "    super().fit(\n",
            "  File \"c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
            "    check_scalar(\n",
            "  File \"c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
            "    raise ValueError(\n",
            "ValueError: min_samples_split == 1, must be >= 2.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.58365802 0.59285666 0.60187509 0.59537956 0.59002841\n",
            " 0.58434303 0.5784671  0.57466248        nan 0.56560656 0.56659862\n",
            " 0.56467988 0.5693657  0.57082338 0.57143474 0.5718601  0.56914931\n",
            "        nan 0.55334219 0.55479319 0.55489543 0.55527559 0.55356226\n",
            " 0.55522241 0.55672264 0.55593169        nan 0.54159825 0.54097508\n",
            " 0.54115371 0.54048078 0.54183731 0.54034428 0.54071117 0.54041127\n",
            "        nan 0.5291867  0.5285073  0.52909863 0.52953531 0.52970298\n",
            " 0.529384   0.5286825  0.52894383        nan 0.58375568 0.59668406\n",
            " 0.5991266  0.59383305 0.58953907 0.58448836 0.58020574 0.57412917\n",
            "        nan 0.56586611 0.56731279 0.56611933 0.57035089 0.57040455\n",
            " 0.57170287 0.57197754 0.56862111        nan 0.55374181 0.55381832\n",
            " 0.55453938 0.55459506 0.55482019 0.55496161 0.55546829 0.55396614\n",
            "        nan 0.54104303 0.54105773 0.54107713 0.54140545 0.54170298\n",
            " 0.54111899 0.54167025 0.5405061         nan 0.52877044 0.52882478\n",
            " 0.52932095 0.529091   0.5289255  0.52888324 0.52889228 0.52912434\n",
            "        nan 0.58423421 0.59226455 0.59922131 0.59525885 0.58902301\n",
            " 0.58382787 0.57819306 0.57389603        nan 0.56632612 0.56568116\n",
            " 0.56711195 0.57046125 0.57093581 0.57067046 0.57249676 0.5691022\n",
            "        nan 0.55458893 0.55452949 0.55386091 0.5537138  0.55427108\n",
            " 0.55472592 0.55626537 0.55429896        nan 0.54179846 0.54155772\n",
            " 0.54088963 0.54138935 0.54025423 0.54147731 0.54143514 0.54009668\n",
            "        nan 0.52890093 0.52894864 0.52891967 0.52834308 0.52938881\n",
            " 0.52879383 0.52896492 0.52869748        nan 0.5838412  0.59347155\n",
            " 0.60002259 0.59336244 0.5908381  0.58419755 0.57910825 0.57441219\n",
            "        nan 0.56757876 0.5667616  0.56564119 0.56977891 0.57134639\n",
            " 0.57318404 0.57183651 0.56768172        nan 0.55440967 0.55431915\n",
            " 0.55410321 0.5545328  0.55464252 0.55477456 0.55551453 0.55414077\n",
            "        nan 0.54166344 0.54134226 0.54114609 0.54071194 0.54059881\n",
            " 0.54212877 0.5409704  0.54022308        nan 0.52846499 0.52872657\n",
            " 0.52899459 0.52914837 0.52876369 0.52862233 0.52883869 0.52883004\n",
            "        nan 0.58464865 0.59306963 0.60041727 0.59398868 0.5897331\n",
            " 0.58472628 0.57899525 0.57516831        nan 0.56536778 0.56463726\n",
            " 0.56598741 0.56788098 0.57146744 0.57370941 0.57171938 0.56871076\n",
            "        nan 0.55475404 0.55522373 0.55461145 0.55543058 0.55461979\n",
            " 0.55401048 0.55607132 0.55522256        nan 0.54135415 0.54121148\n",
            " 0.54123567 0.54119471 0.54126305 0.54089048 0.54130112 0.54042961\n",
            "        nan 0.52899197 0.52865535 0.52886946 0.52918506 0.52882389\n",
            " 0.52898296 0.52893471 0.52848671        nan 0.58362818 0.59189438\n",
            " 0.59875337 0.59368135 0.58999129 0.58462494 0.57806008 0.57433324\n",
            "        nan 0.56751169 0.56316947 0.56497187 0.57035717 0.57308798\n",
            " 0.57058126 0.57050801 0.56836216        nan 0.55427728 0.55423999\n",
            " 0.55526563 0.55426191 0.55455989 0.55434535 0.55684349 0.5545502\n",
            "        nan 0.54125574 0.5411666  0.54113878 0.54115677 0.5412011\n",
            " 0.54201198 0.54122012 0.54055585        nan 0.52845218 0.5293976\n",
            " 0.52871896 0.52895909 0.5288153  0.52873053 0.52873462 0.52893302\n",
            "        nan 0.58556334 0.59465922 0.59932167 0.5955919  0.58976357\n",
            " 0.58532506 0.57916176 0.5747066         nan 0.5654742  0.56522174\n",
            " 0.56722448 0.57003857 0.570031   0.57244174 0.5710515  0.56877236\n",
            "        nan 0.55439184 0.55472248 0.55392676 0.55458401 0.55620499\n",
            " 0.55395069 0.5567741  0.55434223        nan 0.54172454 0.54102887\n",
            " 0.54103892 0.54110111 0.5412938  0.5413693  0.54048166 0.54020009\n",
            "        nan 0.52877026 0.52900473 0.52932507 0.52900011 0.52872061\n",
            " 0.52848631 0.52864909 0.5292187         nan 0.58471242 0.59587397\n",
            " 0.60008908 0.5953114  0.58942392 0.58513207 0.57841041 0.57409735\n",
            "        nan 0.56425243 0.56653232 0.5668353  0.5714376  0.57117115\n",
            " 0.57308923 0.57104039 0.56828398        nan 0.5540172  0.55378592\n",
            " 0.55390348 0.55412693 0.55476805 0.55493366 0.55585461 0.55510133\n",
            "        nan 0.54123294 0.54140163 0.54086248 0.54147042 0.54141395\n",
            " 0.54141464 0.54055438 0.54050886        nan 0.52913054 0.5288971\n",
            " 0.52924274 0.52852227 0.52900911 0.52896259 0.52915708 0.52923846\n",
            "        nan 0.58519825 0.59627593 0.60072305 0.59499491 0.59080297\n",
            " 0.58416384 0.57996952 0.57495803        nan 0.56568867 0.56592073\n",
            " 0.56523738 0.57020071 0.57159351 0.57188693 0.57234493 0.56921889\n",
            "        nan 0.55341912 0.55443307 0.55374211 0.55435896 0.55480198\n",
            " 0.55462105 0.5565435  0.55345106        nan 0.54106726 0.54105326\n",
            " 0.54128156 0.54086141 0.54139481 0.54097914 0.54080022 0.53989961\n",
            "        nan 0.52879307 0.5287878  0.52860314 0.52908424 0.52899974\n",
            " 0.5288452  0.52936854 0.52861289        nan 0.58208899 0.59552361\n",
            " 0.59994235 0.59383679 0.59116914 0.58329267 0.57997235 0.57484621\n",
            "        nan 0.56450753 0.56631857 0.56659836 0.57046769 0.57210638\n",
            " 0.57239401 0.57103733 0.56831472        nan 0.55465746 0.55440748\n",
            " 0.55466483 0.55314143 0.5545112  0.55579324 0.55465977 0.55481849\n",
            "        nan 0.54126161 0.54073315 0.5411006  0.54092855 0.54121676\n",
            " 0.54099759 0.54075002 0.54077022        nan 0.52922333 0.52908033\n",
            " 0.52865307 0.52928553 0.52896338 0.52911091 0.52885346 0.52912567\n",
            "        nan 0.58419201 0.59185802 0.60082761 0.59534337 0.58968552\n",
            " 0.58322334 0.57913007 0.57460504        nan 0.56507496 0.56608075\n",
            " 0.56621891 0.5699839  0.57076273 0.57242567 0.57159109 0.56836551\n",
            "        nan 0.55411845 0.55507821 0.55473592 0.55535585 0.55513929\n",
            " 0.55480877 0.55686841 0.55466429        nan 0.54124028 0.54114354\n",
            " 0.54126998 0.54076254 0.54087803 0.54170325 0.54088019 0.5396825\n",
            "        nan 0.52911013 0.52846498 0.52889195 0.52923139 0.52868129\n",
            " 0.5288199  0.52906272 0.52919797        nan 0.5851865  0.59467032\n",
            " 0.60048601 0.59397872 0.58871049 0.58444893 0.57935433 0.57412869\n",
            "        nan 0.56653742 0.5658351  0.56557811 0.57054564 0.57078474\n",
            " 0.57204247 0.57224094 0.57039922        nan 0.55477237 0.55473029\n",
            " 0.55441726 0.55471635 0.55485493 0.55489604 0.55649969 0.55465117\n",
            "        nan 0.54023908 0.54164776 0.54237982 0.54135331 0.54034894\n",
            " 0.54080588 0.54131927 0.53989498        nan 0.52946314 0.52892941\n",
            " 0.52907448 0.52911777 0.52857617 0.52913587 0.52883263 0.52901293\n",
            "        nan 0.58457124 0.59545077 0.59799472 0.59401126 0.59070157\n",
            " 0.58492131 0.57934095 0.57431191        nan 0.56543819 0.56498892\n",
            " 0.56564503 0.56934685 0.5726803  0.57267792 0.57147392 0.5687243\n",
            "        nan 0.55546808 0.5543523  0.55438867 0.55519269 0.55627161\n",
            " 0.55572073 0.55733478 0.55524171        nan 0.5420512  0.54144178\n",
            " 0.54118532 0.54086658 0.54092677 0.54104128 0.54057609 0.53996773\n",
            "        nan 0.52854069 0.52872818 0.52928392 0.52880279 0.52891934\n",
            " 0.52867071 0.52862771 0.5291234         nan 0.58331426 0.59486913\n",
            " 0.6005381  0.59515566 0.59054071 0.58416453 0.5779624  0.57489007\n",
            "        nan 0.56461661 0.56680424 0.56627544 0.56992955 0.57061384\n",
            " 0.5719725  0.57185056 0.56908614        nan 0.55527121 0.55392405\n",
            " 0.55496594 0.55494452 0.55491873 0.55452366 0.55569078 0.55501745\n",
            "        nan 0.5410059  0.54088805 0.54130492 0.54157819 0.54098302\n",
            " 0.54117134 0.54030461 0.53971896        nan 0.52877203 0.52861931\n",
            " 0.52880067 0.52895517 0.528377   0.52856973 0.52896358 0.52869714\n",
            "        nan 0.58400128 0.5925411  0.60014584 0.59444116 0.59028979\n",
            " 0.58521202 0.58047457 0.5740978         nan 0.56564348 0.56549598\n",
            " 0.56499255 0.56941043 0.57200845 0.5706075  0.57216971 0.56787845\n",
            "        nan 0.55484371 0.55567145 0.55448777 0.55518541 0.55499126\n",
            " 0.55479628 0.55582371 0.5545872         nan 0.54127239 0.54183617\n",
            " 0.54129784 0.54139353 0.54170507 0.54114083 0.5413576  0.54058906\n",
            "        nan 0.5292061  0.52894433 0.5283978  0.52821198 0.52846238\n",
            " 0.52876209 0.52898294 0.5289503         nan 0.58463149 0.59467159\n",
            " 0.59833765 0.59537859 0.59077502 0.58560571 0.57888446 0.57487599\n",
            "        nan 0.56606473 0.5650565  0.56627441 0.57112224 0.5702422\n",
            " 0.57234157 0.57079464 0.56792578        nan 0.5539485  0.55546892\n",
            " 0.55503202 0.55430703 0.55474875 0.55382259 0.55677557 0.55424318\n",
            "        nan 0.54147614 0.54125214 0.54073416 0.54114733 0.54134865\n",
            " 0.54085133 0.54080707 0.54007777        nan 0.52933909 0.52905262\n",
            " 0.5290244  0.52891718 0.52853866 0.52865632 0.52896096 0.52853021\n",
            "        nan 0.58332737 0.59570906 0.60006205 0.59566888 0.59075466\n",
            " 0.58470882 0.57821759 0.57460722        nan 0.56591848 0.56739049\n",
            " 0.56498612 0.56906652 0.57084954 0.57286012 0.57026108 0.56950499\n",
            "        nan 0.55484011 0.55522764 0.55452491 0.55434611 0.55409941\n",
            " 0.55393433 0.55596583 0.55410916        nan 0.54100857 0.54064481\n",
            " 0.54109506 0.54005773 0.54119516 0.54054062 0.54136188 0.54094045\n",
            "        nan 0.52906608 0.52912917 0.52921253 0.52891685 0.52927642\n",
            " 0.52947142 0.52882008 0.52897193        nan 0.58488869 0.59613053\n",
            " 0.59979911 0.59569421 0.58963677 0.58385032 0.57812597 0.57454291\n",
            "        nan 0.56646973 0.56660422 0.56593368 0.5695202  0.5722214\n",
            " 0.57188077 0.5714665  0.56790121        nan 0.55370138 0.55443114\n",
            " 0.55554973 0.55490922 0.55388468 0.55437724 0.55605178 0.55485859\n",
            "        nan 0.54072072 0.54008395 0.54049335 0.54100655 0.5409306\n",
            " 0.5412086  0.54116204 0.54068062        nan 0.52922933 0.52851452\n",
            " 0.52902988 0.52895854 0.52931158 0.52900086 0.52875043 0.52905333\n",
            "        nan 0.58574327 0.59612106 0.60137331 0.59395388 0.59000038\n",
            " 0.5837392  0.57957032 0.57437578        nan 0.56547208 0.56617106\n",
            " 0.5664606  0.57022493 0.57212832 0.57172224 0.57087355 0.5681152\n",
            "        nan 0.55484029 0.55396565 0.55475187 0.5553895  0.55439946\n",
            " 0.55484376 0.55629122 0.5550167         nan 0.54063744 0.54144604\n",
            " 0.54088899 0.54162956 0.54102834 0.54094088 0.54066622 0.54049277\n",
            "        nan 0.52829463 0.52900811 0.52886192 0.52880812 0.52899851\n",
            " 0.52918885 0.52949742 0.52885688        nan 0.58325788 0.59442354\n",
            " 0.59964056 0.59535741 0.58910141 0.58482698 0.57992932 0.57593839\n",
            "        nan 0.56596829 0.56523291 0.56747901 0.57071771 0.57136045\n",
            " 0.57197129 0.57135476 0.57054522        nan 0.55547458 0.55468676\n",
            " 0.55350875 0.55553996 0.55450612 0.55465419 0.55559325 0.55417059\n",
            "        nan 0.54202053 0.54203434 0.54053584 0.54125696 0.5410203\n",
            " 0.5408567  0.54090196 0.53994659        nan 0.52910739 0.52875147\n",
            " 0.52926433 0.52852927 0.52899885 0.5290536  0.5289733  0.52898473]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_dist = {\n",
        "       'max_depth': np.arange(50, 200, 1),\n",
        "    'min_samples_split': np.arange(1, 200, 1),\n",
        "    'min_samples_leaf': [1, 200, 1],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "rs = RandomizedSearchCV(dt, param_distributions=param_dist, scoring='f1_weighted', cv=5,   n_jobs=-1,\n",
        "                                 verbose= 1, n_iter=100)\n",
        "\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': np.arange(max(best_params['max_depth']-5, 1), best_params['max_depth']+5, 1),\n",
        "    'min_samples_split': np.arange(max(best_params['min_samples_split']-5, 1), best_params['min_samples_split']+5, 1),\n",
        "    'min_samples_leaf': np.arange(max(best_params['min_samples_leaf']-2 , 1), best_params['min_samples_leaf']+5, 1),\n",
        "    'max_features': [best_params['max_features'], None]\n",
        "}\n",
        "\n",
        "\n",
        "# Perform grid search CV with the defined parameter grid\n",
        "gs = GridSearchCV(dt, param_grid=param_grid, scoring='f1_weighted', cv=5,   n_jobs=-1,\n",
        "                                 verbose= 1)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "best_params_gs = gs.best_params_\n",
        "dt_best = DecisionTreeClassifier(**best_params_gs)\n",
        "\n",
        "dt_best.fit(X_train, y_train)\n",
        "y_pred = dt_best.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"D-Tree, Grid Search CV\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n",
        "print(f\"Model: D-Tree: Grid Search CV, \\nData: X_test\\n Accuracy={accuracy:.7f}\\n Precision={precision:.7f}\\n Recall={recall:.7f}\\n F1={f1:.7f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4MZQRgH9bTN"
      },
      "source": [
        "### Random Forest: Random Search CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJWDD-GD9bTN",
        "outputId": "cad2246c-d627-4a64-b93d-08748f364829"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:910: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: D-Tree, best parameters: {'n_estimators': 70, 'min_samples_split': 140, 'min_samples_leaf': 14, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 60, 'max_features': 'sqrt', 'max_depth': 84, 'criterion': 'gini'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\rahul\\AppData\\Local\\Temp\\ipykernel_25144\\3898013389.py:24: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  rf_best.fit(X_train, y_train)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: Random Forest: Grid Search CV, \n",
            "Data: X_test\n",
            " Accuracy=0.3837654\n",
            " Precision=0.2906679\n",
            " Recall=0.1950383\n",
            " F1=0.1881577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "param_grid = {\n",
        "        \"n_estimators\" : np.arange(50, 90, 10),\n",
        "        \"criterion\" : ['gini', 'entropy' ],\n",
        "        \"max_depth\" : np.arange(70, 150),\n",
        "        \"min_samples_split\" : np.arange(10,200, 10),\n",
        "        \"min_samples_leaf\" : np.arange(10, 100),\n",
        "        \"max_features\" : ['sqrt','log2'],\n",
        "        \"max_leaf_nodes\" : np.arange(10, 70, 10),\n",
        "        \"min_impurity_decrease\" : np.logspace(-8 , 6 )\n",
        "        \n",
        "}\n",
        "\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rs = RandomizedSearchCV(rf, param_distributions=param_grid, scoring='f1_weighted', cv=5,   n_jobs=-1,\n",
        "                                 verbose= 1, n_iter=100)\n",
        "\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "best_params = rs.best_params_\n",
        "print(f\"Model: D-Tree, best parameters: {best_params}\")\n",
        "rf_best = RandomForestClassifier(**best_params)\n",
        "\n",
        "rf_best.fit(X_train, y_train)\n",
        "y_pred = rf_best.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Model: Random Forest: Grid Search CV, \\nData: X_test\\n Accuracy={accuracy:.7f}\\n Precision={precision:.7f}\\n Recall={recall:.7f}\\n F1={f1:.7f}\")\n",
        "\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"Random Forest, Random Search CV\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-MQBNAD9bTO"
      },
      "source": [
        "### Gradient Boost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dS1aEKob9bTO"
      },
      "outputs": [],
      "source": [
        "\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'learning_rate': [0.01, 0.1, 0.5],\n",
        "    'max_depth': [3, 5, 7, 9]\n",
        "}\n",
        "\n",
        "\n",
        "gboost = GradientBoostingClassifier()\n",
        "rs = RandomizedSearchCV(gboost, param_distributions=param_grid, scoring='f1_weighted', cv=5,   n_jobs=-1,\n",
        "                                 verbose= 1, n_iter=100)\n",
        "\n",
        "rs.fit(X_train, y_train)\n",
        "\n",
        "best_params = rs.best_params_\n",
        "print(f\"Model: Gradient: Boost Random Search, best parameters: {best_params}\")\n",
        "rf_best = RandomForestClassifier(**best_params)\n",
        "\n",
        "rf_best.fit(X_train, y_train)\n",
        "y_pred = rf_best.predict(X_test)\n",
        "\n",
        "# Calculate the F1 score of the predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Model: Random Forest: Grid Search CV, \\nData: X_test\\n Accuracy={accuracy:.7f}\\n Precision={precision:.7f}\\n Recall={recall:.7f}\\n F1={f1:.7f}\")\n",
        "\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"Gradient Boost, Random Search CV\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nFmOBOyHNYs"
      },
      "source": [
        "the gradient search seems to be taking a long time( > 20 min , for single eexcution). Hence i am omitting this apprach from my analysis. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ4FyiGWHXwl"
      },
      "source": [
        "### SVM : Linear "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_OnijkbHdNS",
        "outputId": "4fed2e38-2a8c-4e64-a390-8491f3eac93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: X_test, Accuracy=0.4400057 Precision=0.4395772 Recall=0.4037509 F1=0.3974552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "svm_lin_model = SVC(kernel=\"linear\").fit(X_train, np.ravel(y_train))\n",
        "y_pred = svm_lin_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Data: X_test, Accuracy={accuracy:.7f} Precision={precision:.7f} Recall={recall:.7f} F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM linear\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfISYz7VQJtD"
      },
      "source": [
        "### SVM: RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsstA-8aPjDH",
        "outputId": "8e349ab3-2dab-4e3a-c71f-87ebd10d3df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: X_test, Accuracy=0.7420314 Precision=0.6519994 Recall=0.5889538 F1=0.5978304\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "svm_lin_model = SVC(kernel=\"rbf\").fit(X_train, np.ravel(y_train))\n",
        "y_pred = svm_lin_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Data: X_test, Accuracy={accuracy:.7f} Precision={precision:.7f} Recall={recall:.7f} F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM rbf\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGooqBx3Qot6"
      },
      "source": [
        "### SVM: Poly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvvPGVCoQmCw",
        "outputId": "e3d94cbb-2a2e-4766-83fd-3cbe329bd75d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data: X_test, Accuracy=0.7869387 Precision=0.6889031 Recall=0.6385982 F1=0.6535654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "svm_lin_model = SVC(kernel=\"poly\").fit(X_train, np.ravel(y_train))\n",
        "y_pred = svm_lin_model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average= 'macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Data: X_test, Accuracy={accuracy:.7f} Precision={precision:.7f} Recall={recall:.7f} F1={f1:.7f}\")\n",
        "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM poly\", \n",
        "                                                    'Accuracy': [accuracy], \n",
        "                                                    'Precision': [precision], \n",
        "                                                    'Recall': [recall], \n",
        "                                                    'F1': [f1]\n",
        "                                                     }, index=[0])])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "W6SFh1tHQ32y",
        "outputId": "2b33c5ea-eeb3-4eee-8046-52698ef617ab"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.742031</td>\n",
              "      <td>0.738658</td>\n",
              "      <td>0.742031</td>\n",
              "      <td>0.737258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM poly</td>\n",
              "      <td>0.786939</td>\n",
              "      <td>0.688903</td>\n",
              "      <td>0.638598</td>\n",
              "      <td>0.653565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D-Tree, Random Search CV</td>\n",
              "      <td>0.636209</td>\n",
              "      <td>0.634295</td>\n",
              "      <td>0.636209</td>\n",
              "      <td>0.634313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D Tree Unpruned</td>\n",
              "      <td>0.614251</td>\n",
              "      <td>0.616492</td>\n",
              "      <td>0.614251</td>\n",
              "      <td>0.615006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.616660</td>\n",
              "      <td>0.610132</td>\n",
              "      <td>0.616660</td>\n",
              "      <td>0.609574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.616660</td>\n",
              "      <td>0.610132</td>\n",
              "      <td>0.616660</td>\n",
              "      <td>0.609574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM rbf</td>\n",
              "      <td>0.742031</td>\n",
              "      <td>0.651999</td>\n",
              "      <td>0.588954</td>\n",
              "      <td>0.597830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>D-Tree, Grid Search CV</td>\n",
              "      <td>0.640884</td>\n",
              "      <td>0.561359</td>\n",
              "      <td>0.574426</td>\n",
              "      <td>0.566588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM linear</td>\n",
              "      <td>0.440006</td>\n",
              "      <td>0.439577</td>\n",
              "      <td>0.403751</td>\n",
              "      <td>0.397455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Random Forest, Random Search CV</td>\n",
              "      <td>0.383765</td>\n",
              "      <td>0.290668</td>\n",
              "      <td>0.195038</td>\n",
              "      <td>0.188158</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             model  Accuracy  Precision    Recall        F1\n",
              "0                              SVM  0.742031   0.738658  0.742031  0.737258\n",
              "0                         SVM poly  0.786939   0.688903  0.638598  0.653565\n",
              "0         D-Tree, Random Search CV  0.636209   0.634295  0.636209  0.634313\n",
              "0                  D Tree Unpruned  0.614251   0.616492  0.614251  0.615006\n",
              "0                    Random Forest  0.616660   0.610132  0.616660  0.609574\n",
              "0                    Random Forest  0.616660   0.610132  0.616660  0.609574\n",
              "0                          SVM rbf  0.742031   0.651999  0.588954  0.597830\n",
              "0           D-Tree, Grid Search CV  0.640884   0.561359  0.574426  0.566588\n",
              "0                       SVM linear  0.440006   0.439577  0.403751  0.397455\n",
              "0  Random Forest, Random Search CV  0.383765   0.290668  0.195038  0.188158"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "performance.sort_values(by=['F1'], ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBzCE_dsSF0p"
      },
      "source": [
        "## Observations:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bko86hNpSG1n"
      },
      "source": [
        "### Models that failed to compute:\n",
        "Grid Search for all these models: Gradient Boost, Random Forest and SVM. \n",
        "\n",
        "### Reason:\n",
        "with the limited computational power , i've tried to run a couple of executions on these models. However, the execution time is execeeding 20minutes on each model. Hence I had to ommit these executions. The reason is probably the complex operations and iterations that might require to do and the size of data ( 23k) on training set. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTqc28vjSaLA"
      },
      "source": [
        "##  Results and discussions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uo2C5u11S28g"
      },
      "source": [
        "1. Decision Tree and SVM models have produced a good accuracy scores and a fair enough f1-scores.\n",
        "2. Especially the defualt SVM model produced a 75% accuracy , precision and recall. Which is substantially high compared to the rest of models.\n",
        "3. However the accuracy of SVM with kernel 'Poly' produced an accuracy of 78% , but we have decrease in f1-score. \n",
        "\n",
        "\n",
        "### Scope: \n",
        "\n",
        "There is a need for trying different parameters (Random, Grid Search) on SVM model. to find a best model for our chess data.\n",
        "But for now , i would go for a the default SVM model, which has a fairly high metrics all, accuracy, precision, recall and f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwD_zjHETYY9"
      },
      "source": [
        "## Best model: based on the computational power and analysis done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NNd1EzqCTeU1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.742031</td>\n",
              "      <td>0.738658</td>\n",
              "      <td>0.742031</td>\n",
              "      <td>0.737258</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model  Accuracy  Precision    Recall        F1\n",
              "0   SVM  0.742031   0.738658  0.742031  0.737258"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "performance.loc[performance['model'] == 'SVM']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## we 07 assignment : Neural Networks \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=[100, 60])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=[100, 60])</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(hidden_layer_sizes=[100, 60])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ann = MLPClassifier(hidden_layer_sizes=[100, 60], solver='adam', max_iter=200)\n",
        "ann.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.83      0.77         6\n",
            "           1       0.79      0.58      0.67        19\n",
            "           2       0.90      0.87      0.89        71\n",
            "           3       0.71      0.60      0.65        25\n",
            "           4       0.67      0.71      0.69        65\n",
            "           5       0.73      0.73      0.73       138\n",
            "           6       0.72      0.74      0.73       168\n",
            "           7       0.78      0.65      0.71       208\n",
            "           8       0.73      0.75      0.74       445\n",
            "           9       0.70      0.76      0.73       512\n",
            "          10       0.76      0.63      0.69       597\n",
            "          11       0.70      0.76      0.73       841\n",
            "          12       0.79      0.77      0.78      1063\n",
            "          13       0.86      0.88      0.87      1305\n",
            "          14       0.00      0.00      0.00         7\n",
            "          15       0.94      0.94      0.94       666\n",
            "          16       0.90      0.92      0.91       115\n",
            "          18       0.94      0.94      0.94       808\n",
            "\n",
            "    accuracy                           0.81      7059\n",
            "   macro avg       0.74      0.73      0.73      7059\n",
            "weighted avg       0.81      0.81      0.81      7059\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred=y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Observations; Neural Net\n",
        "\n",
        "\n",
        "1. after trying different combinations of hidden layers, i found best scores for this combination (100, 60). \n",
        "2. Considering the imbalance in data, we have decided to choose, macro weighted average for calculating our metrics.and\n",
        "3. Our ANN produces are quite similar scores as our best model above (SVM).\n",
        "4. There is scope for improvement using ANN, as we can try parameter tunning and find a best possible score for different range of hudeen layers. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1118: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100,), 'activation': 'relu'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "param_dist = {\n",
        "    'hidden_layer_sizes': [(10,), (50,), (100,), (10,10), (50,50), (100,100)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'learning_rate': ['constant', 'adaptive']\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    mlp, param_distributions=param_dist, n_iter=10, cv=5,verbose=-1)\n",
        "\n",
        "# Fit the model on training data\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Best parameters:\", random_search.best_params_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.75\n",
            "Precision: 0.66\n",
            "Recall: 0.67\n",
            "F1-score: 0.66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rahul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on test data\n",
        "y_pred = random_search.predict(X_test)\n",
        "\n",
        "# Calculate scores\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "\n",
        "# Print the scores\n",
        "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
        "print(\"Precision: {:.2f}\".format(precision))\n",
        "print(\"Recall: {:.2f}\".format(recall))\n",
        "print(\"F1-score: {:.2f}\".format(f1))\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Observations: ANN, Random search CV\n",
        "we improved the accuracy by 1 % but our precision and recall has dropped by 10%, i think the initial ANN with (100, 60) has produced best scores. We can try more ranges of parameters for a good score. but it is not optimal as the execution on RandomSearch is taking 9 minutes. \n",
        "\n",
        "Therefore the best Model : ANN with hidden layers (100, 60)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "P4MZQRgH9bTN",
        "7-MQBNAD9bTO",
        "EZ4FyiGWHXwl",
        "WfISYz7VQJtD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
